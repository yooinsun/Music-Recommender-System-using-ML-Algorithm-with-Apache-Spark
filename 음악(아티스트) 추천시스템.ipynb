{
 "metadata": {
  "name": "Spark_음악(아티스트)_추천_시스템_(by ALS)_python",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import Library\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from cassandra.concurrent import execute_concurrent_with_args\n",
    "from cassandra.cluster import Cluster\n",
    "from pyspark.sql.types import IntegerType"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Spark session 생성\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set('spark.app.name', 'recomm_music')\n",
    "conf.set(\"spark.jars.packages\", 'com.redislabs:spark-redis_2.12:3.1.0')\n",
    "conf.set(\"spark.redis.connection.host\", \"127.0.0.1\")\n",
    "conf.set(\"spark.redis.connection.port\", \"6379\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "%load_ext sparksql_magic\n",
    "%config SparkSql.limit= 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Spark 버전 및 정보 확인\n",
    "print(spark.version)\n",
    "print(spark.sparkContext.master)\n",
    "print(spark.sparkContext.sparkUser())\n",
    "print(f'hadoop version = {spark._jvm.org.apache.hadoop.util.VersionInfo.getVersion()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 데이터 수집\n",
    "- 다운로드 및 HDFS 업로드\n",
    "- ```https://storage.googleapis.com/aas-data-sets/profiledata_06-May-2005.tar.gz```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mkdir -p \"/Users/yooinsun/data/audio\"\n",
    "!wget -O /Users/yooinsun/data/audio/profiledata_06-May-2005.tar.gz https://storage.googleapis.com/aas-data-sets/profiledata_06-May-2005.tar.gz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!tar xvfz ../data/audio/profiledata_06-May-2005.tar.gz -C ../data/audio\n",
    "!ls -alh ../data/audio/profiledata_06-May-2005"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#export HADOOP_USER_NAME=spark\n",
    "!../hadoop-3.3.6/bin/hdfs dfs -mkdir -p /data/audio\n",
    "!../hadoop-3.3.6/bin/hdfs dfs -put -f /data/audio/profiledata_06-May-2005 /data/audio\n",
    "\n",
    "!../hadoop-3.3.6/bin/hdfs dfs -ls -h /data/audio\n",
    "!../hadoop-3.3.6/bin/hdfs dfs -ls -h /data/audio/profiledata_06-May-2005"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!../hadoop-3.3.6/bin/hdfs dfs -cat /data/audio/profiledata_06-May-2005/README.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!../hadoop-3.3.6/bin/hdfs dfs -cat /data/audio/profiledata_06-May-2005/user_artist_data.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!../hadoop-3.3.6/bin/hdfs dfs -cat /data/audio/profiledata_06-May-2005/artist_data.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!../hadoop-3.3.6/bin/hdfs dfs -cat /data/audio/profiledata_06-May-2005/artist_alias.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 데이터 탐색, 데이터 정렬\n",
    "\n",
    "\n",
    "```\n",
    "\"Music Listening Dataset\" (Audioscrobbler.com => https://last.fm/) \n",
    "-> 6 May 2005, for around 150,000 real people\n",
    "-> Audioscrobbler is receiving around 2 million song submissions per day\n",
    "(https://ko.wikipedia.org/wiki/%EB%9D%BC%EC%8A%A4%ED%8A%B8_FM, https://namu.wiki/w/Last.fm)\n",
    "''''\n",
    "scrobble\t미국·영국 [|skrɒbəl]  [VERB] (of an online music service) to record a listener's musical preferences and recommend similar music that he or she might enjoy\n",
    "```\n",
    "\n",
    "- user_artist_data.txt\n",
    "    - 3 columns: userid artistid playcount => 공백(' ')으로 구분됨\n",
    "    \n",
    "    - 형식 : ```유저(공백)아티스트(공백)플레이카운트```\n",
    "        - ex) 1052430 2032445 12 =>\t2032445\t신화 (Shinhwa)\n",
    "     \n",
    "- artist_data.txt\n",
    "    - 2 columns: artistid artist_name\t=> 탭('\\t')으로 구분됨\n",
    "    \n",
    "    - 형식 :  ```아티스트(탭)이름```\n",
    "        - ex) 한글 아티스트 이름 (다나, 클래지콰이, 윤건, 엠씨더맥스, 음악가 없음, 유미, 김성필, 엠 투 엠, 신부수업 OST, 데이슬리퍼, 신화 (Shinhwa), 베이비 복스, 윤도현)\n",
    "        - ex) 2032445\t신화 (Shinhwa)\n",
    "    \n",
    "- artist_alias.txt\n",
    "    - 2 columns: badid goodid\t=> 탭('\\t')으로 구분됨\n",
    "    - known incorrectly spelt artists and the correct artist id. you can correct errors in user_artist_data as you read it in using this file\n",
    "\n",
    "    - 형식 : ```배드아이디(탭)굿아이디```    \n",
    "        - ex) 2032445\t6834637\n",
    "        - ex) 2032445\t신화 (Shinhwa) : 6834637\t신화\n",
    "        - ex) 10103564\t베이비 복스 : 1101679\tBaby V.O.X\n",
    "        - ex) 2101369\tBaby Vox 3 : 1101679\tBaby V.O.X\n",
    "        - ex) 1028894\tBaby Vox : 1101679\tBaby V.O.X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "user_artist_data.txt 정보 확인\n",
    "- text method 로 txt 읽기\n",
    "- csv method 로 txt 읽기\n",
    "- describe(), summary() 를 통해, 데이터 살펴보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistDS = spark.read.text(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/user_artist_data.txt\")\n",
    "\n",
    "print(userArtistDS.count())\n",
    "userArtistDS.printSchema()\n",
    "userArtistDS.show()\n",
    "\n",
    "# #scala\n",
    "# val userArtistDS = spark\n",
    "#     .read\n",
    "#     .textFile(\"hdfs://spark-master-01:9000/data/audio/profiledata_06-May-2005/user_artist_data.txt\")  //--spark.read.textFile(path)\n",
    "# \n",
    "# println(userArtistDS.count())\n",
    "# userArtistDS.printSchema()\n",
    "# userArtistDS.show()\n",
    "# z.show(userArtistDS.limit(20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistCSVDF = spark.read.option(\"sep\", \" \").csv(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/user_artist_data.txt\").toDF(\"userid\", \"artistid\", \"playcount\")\n",
    "\n",
    "print(userArtistCSVDF.count())\n",
    "print(userArtistDS.count() - userArtistCSVDF.count())\n",
    "userArtistCSVDF.printSchema()\n",
    "userArtistCSVDF.show()\n",
    "\n",
    "# # scalar\n",
    "# val userArtistCSVDF = spark\n",
    "#     .read\n",
    "#     .option(\"sep\", \" \")\n",
    "#     .csv(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/user_artist_data.txt\")  //--spark.read.csv(path)....\n",
    "#     .toDF(\"userid\", \"artistid\", \"playcount\")\n",
    "# \n",
    "# println(userArtistCSVDF.count())\n",
    "# println(userArtistDS.count() - userArtistCSVDF.count())\n",
    "# userArtistCSVDF.printSchema()\n",
    "# userArtistCSVDF.show()\n",
    "# z.show(userArtistCSVDF.limit(20))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistCSVDF.describe().show()  #--DataFrame.describe()...."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistCSVDF.summary().show()  #-DataFrame.summary()...."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "통계정보 확인 했을떄, 이상데이터 발견\n",
    "- 확인 방법: describe() 와 summary() 를 활용하여 데이터 통계 확인\n",
    "- 이상 데이터: min, max, 25%, 50%, 75% 수치가 비정상적임을 확인함\n",
    "- 조치 방안: 각 column type 을 string -> int 로 변경"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistCSVDF2 = userArtistCSVDF.selectExpr(\"cast(userid as int)\", \"cast(artistid as int)\", \"cast(playcount as int)\")\n",
    "userArtistCSVDF2.printSchema()\n",
    "\n",
    "# scala\n",
    "# val userArtistCSVDF2 = userArtistCSVDF\n",
    "#     .selectExpr(\"cast(userid as int)\", \"cast(artistid as int)\", \"cast(playcount as int)\")  //--cast(col as type)....\n",
    "# \n",
    "# userArtistCSVDF2.printSchema"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# type(str->int) 변경 후, 통계정보 재확인\n",
    "userArtistCSVDF2.summary().show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistCSVDF2.where(\"playcount = 439771\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "[ playcount = 439771의 의미? ]\n",
    "\n",
    "=> 음악 한곡당 4분이라 가정할 경우, 쉬지않고 연속으로 약 3.34년 동안 음악을 들은 것\n",
    "'''\n",
    "\n",
    "print((4 * 439771) /60/ 24/ 365)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "[ 해당 프로젝트에서 max palycount 값 정하는 기준 ]\n",
    "\n",
    "- 기준은 6개월이 최대치라고 설정함 + 음악 한곡당 4분이라 가정함\n",
    "- max plyacount 값은 64800 으로 설정함\n",
    "'''\n",
    "\n",
    "print((60 * 24 * 30 * 6) / 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "새로운 Column 추가하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistCSVDF2.where(userArtistCSVDF2.playcount > 64800).withColumn('playyear', F.round(*[userArtistCSVDF2.playcount * 4 / 60/ 24/365] , 3)).orderBy('playcount', ascending=False).show()\n",
    "\n",
    "# # scala\n",
    "# userArtistCSVDF2\n",
    "#     .where($\"playcount\" > 64800)\n",
    "#     .withColumn(\"playyear\", round('playcount * 4 / 60F / 24L / 365F, 3))\n",
    "#     .orderBy('playcount.desc)\n",
    "#     .show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistCSVDF3 = userArtistCSVDF2.filter(userArtistCSVDF2.playcount <= 64800)\n",
    "userArtistCSVDF3.persist(StorageLevel.MEMORY_ONLY)\n",
    "print(userArtistCSVDF3.count())\n",
    "userArtistCSVDF3.printSchema()\n",
    "userArtistCSVDF3.show()\n",
    "\n",
    "#scala\n",
    "# val userArtistCSVDF3 = userArtistCSVDF2\n",
    "#     .filter(\"playcount <= 64800\")\n",
    "# \n",
    "# userArtistCSVDF3.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)\n",
    "# println(userArtistCSVDF3.count())\n",
    "# userArtistCSVDF3.printSchema()\n",
    "# userArtistCSVDF3.show()\n",
    "# z.show(userArtistCSVDF3.limit(20))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistCSVDF3.storageLevel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(userArtistDS.count() - userArtistCSVDF3.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "artist_data.txt (아티스트_이름)\n",
    "- text method 로 txt 읽기\n",
    "- csv method 로 txt 읽기\n",
    "- describe(), summary() 를 통해, 데이터 살펴보기\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#python\n",
    "artistDS = spark.read.text(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/artist_data.txt\") # \"hdfs://spark-master-01:9000/data/audio/profiledata_06-May-2005/artist_data.txt\"\n",
    "\n",
    "print(artistDS.count())\n",
    "artistDS.printSchema()\n",
    "artistDS.show(truncate=False)\n",
    "\n",
    "# scala\n",
    "# val artistDS = spark\n",
    "#     .read\n",
    "#     .textFile(\"hdfs://spark-master-01:9000/data/audio/profiledata_06-May-2005/artist_data.txt\")\n",
    "# \n",
    "# println(artistDS.count())\n",
    "# artistDS.printSchema()\n",
    "# artistDS.show(truncate=false)\n",
    "# z.show(artistDS.limit(20))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "artistDF = spark.read.option(\"sep\", \"\\t\").option(\"inferSchema\", True).csv(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/artist_data.txt\").toDF(\"artistid\", \"artistname\") # inferSchema 옵션은, schema를 Spark이 자동으로 알아내는 경우 사용\n",
    "    \n",
    "print(artistDF.count())\n",
    "print(artistDS.count() - artistDF.count())\n",
    "artistDF.printSchema()\n",
    "artistDF.show()\n",
    "\n",
    "# scala\n",
    "# val artistDF = spark\n",
    "#     .read\n",
    "#     .option(\"sep\", \"\\t\")\n",
    "#     .option(\"inferSchema\", true)  //--inferSchema => true....\n",
    "#     .csv(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/artist_data.txt\")\n",
    "#     .toDF(\"artistid\", \"artistname\")\n",
    "#     \n",
    "# println(artistDF.count())\n",
    "# println(artistDS.count() - artistDF.count())\n",
    "# artistDF.printSchema()\n",
    "# artistDF.show(false)\n",
    "# z.show(artistDF.limit(20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "artistDF.summary().show() "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "오류 데이터(artistid toInt 타입변환이 안되는 경우) 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "@F.udf\n",
    "def str_to_int(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "artistDF.withColumn(\"artistid_toInt\",str_to_int(artistDF.artistid)).where(\"artistid_toInt is null\").show()\n",
    "artistDF.withColumn(\"artistid_toInt\",str_to_int(artistDF.artistid)).where(\"artistid_toInt is null\").summary().show()\n",
    "\n",
    "# scala\n",
    "# artistDF.filter(row => {\n",
    "#     val artistid = row.getString(0)\n",
    "#     val artistname = row.getString(1)\n",
    "#     try {\n",
    "#         artistid.toInt\n",
    "#         false\n",
    "#     } catch {\n",
    "#         case e:Exception => true  //--int로 형변환이 되지 않는 것만 필터링해서 살펴보자....\n",
    "#     }\n",
    "#     \n",
    "# }).show(false)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "오류 데이터 제거"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "artistFinal = artistDF.withColumn(\"artistid\",str_to_int(artistDF.artistid)).where(\"artistid is not null\").where('artistname is not null').selectExpr(\"cast(artistid as int) artistid\", 'artistname')\n",
    "print(artistFinal.count())\n",
    "artistFinal.printSchema()\n",
    "artistFinal.show()\n",
    "\n",
    "# scala\n",
    "# val artistFinal = artistDF.filter(row => {\n",
    "#     val artistid = row.getString(0)\n",
    "#     val artistname = row.getString(1)\n",
    "#     try {\n",
    "#         artistid.toInt\n",
    "#         true\n",
    "#     } catch {\n",
    "#         case e:Exception => false  //--int로 형변환이 되지 않는 것은 버리자....\n",
    "#     }\n",
    "# })\n",
    "# .where(\"artistid is not null\")\n",
    "# .where(\"artistname is not null\")\n",
    "# .withColumn(\"artistid\", expr(\"cast(artistid as int)\"))\n",
    "# \n",
    "# println(artistFinal.count())\n",
    "# artistFinal.printSchema()\n",
    "# artistFinal.show(false)\n",
    "# z.show(artistFinal.limit(20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "artistFinal.summary().show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 아티스트 이름이 null인 데이터 확인\n",
    "artistFinal.where(\"artistname is null\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#아티스트 이름이 이상한(숫자) 데이터 확인\n",
    "artistFinal.where(\"artistname in ('33', '304', '1988')\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#아티스트 이름이 이상한(숫자) 데이터 확인\n",
    "artistDS.where(\"value like '1335772%' or value like '1344623%' or value like '2032179%'\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#아티스트 이름이 이상한(min/max) 데이터 확인\n",
    "artistFinal.where(\"artistname in ('\u0001', '￿￿￿￿￿￿￿￿￿￿￿￿くȁ')\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "artistFinal.where(\"artistname in (' ', '￿￿￿￿￿￿￿￿￿￿￿￿くȁ')\").show()\n",
    "artistFinal.where(\"artistname in ('.', '￿￿￿￿￿￿￿￿￿￿￿￿くȁ')\").show()\n",
    "artistFinal.where(\"artistname in ('\u0001', '￿￿￿￿￿￿￿￿￿￿￿￿くȁ')\").show()\n",
    "\n",
    "artistDS.where(\"value like '6986651%' or value like '9915481%' or value like '1025136%' or value like '1165062%'\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "artistDS.where(\"value like '1165062%' or value like '10495051%'\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 걸러진 데이터 건수 확인\n",
    "print(artistDS.count() - artistFinal.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (3) artist_alias.txt (배드아이디_굿아이디)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "artistAliasDS = spark.read.text(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/artist_alias.txt\") # hdfs://spark-master-01:9000/data/audio/profiledata_06-May-2005/artist_alias.txt\n",
    "    \n",
    "print(artistAliasDS.count())\n",
    "artistAliasDS.printSchema()\n",
    "artistAliasDS.show()\n",
    "\n",
    "#scala\n",
    "# val artistAliasDS = spark\n",
    "#     .read\n",
    "#     .textFile(\"hdfs://spark-master-01:9000/data/audio/profiledata_06-May-2005/artist_alias.txt\")\n",
    "#     \n",
    "# println(artistAliasDS.count())\n",
    "# artistAliasDS.printSchema()\n",
    "# artistAliasDS.show()\n",
    "# z.show(artistAliasDS.limit(20))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "artistAliasDF = spark.read.option(\"sep\", \"\\t\").option(\"inferSchema\", True).csv(\"hdfs://localhost:9000/data/audio/profiledata_06-May-2005/artist_alias.txt\").toDF(\"badid\", \"goodid\") # hdfs://spark-master-01:9000/data/audio/profiledata_06-May-2005/artist_alias.txt\n",
    "print(artistAliasDF.count())\n",
    "artistAliasDF.printSchema()\n",
    "artistAliasDF.show()\n",
    "\n",
    "# scala\n",
    "# val artistAliasDF = spark\n",
    "#     .read\n",
    "#     .option(\"sep\", \"\\t\")\n",
    "#     .option(\"inferSchema\", true)  //--inferSchema => true....\n",
    "#     .csv(\"hdfs://spark-master-01:9000/data/audio/profiledata_06-May-2005/artist_alias.txt\")\n",
    "#     .toDF(\"badid\", \"goodid\")\n",
    "#     \n",
    "# println(artistAliasDF.count())\n",
    "# artistAliasDF.printSchema()\n",
    "# artistAliasDF.show()\n",
    "# z.show(artistAliasDF.limit(20))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 통계정보 확인\n",
    "artistAliasDF.summary().show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "summary() 의 count 정보를 확인했을때, badid 와 goodid 의 개수가 일치하지 않음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "artistAliasDF.where(\"badid is null\").show(truncate=False)\n",
    "artistAliasDF.filter(\"goodid is null\").show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터에서 Null 제거"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "artistAliasFinal = artistAliasDF.filter(\"badid is not null\").filter(\"goodid is not null\")\n",
    "\n",
    "print(artistAliasFinal.count())\n",
    "artistAliasFinal.printSchema()\n",
    "artistAliasFinal.show()\n",
    "\n",
    "artistAliasFinal.createOrReplaceTempView(\"artistAliasFinal\")\n",
    "\n",
    "# scala\n",
    "# val artistAliasFinal = artistAliasDF\n",
    "#     .filter(\"badid is not null\")\n",
    "#     .filter(\"goodid is not null\")\n",
    "# \n",
    "# println(artistAliasFinal.count())\n",
    "# artistAliasFinal.printSchema()\n",
    "# artistAliasFinal.show()\n",
    "# z.show(artistAliasFinal.limit(20))\n",
    "# \n",
    "# artistAliasFinal.createOrReplaceTempView(\"artistAliasFinal\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "artistAliasFinal.summary().show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 걸러진 데이터 건수 확인\n",
    "print(artistAliasDS.count() - artistAliasFinal.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(4) user_artist_data.txt(유저_아티스트_플레이카운트 데이터) 에서 아티스트의 BadID를 GoodID로 변경하는 작업수행\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TempView 등록\n",
    "userArtistCSVDF3.printSchema()\n",
    "artistAliasFinal.printSchema()\n",
    "\n",
    "userArtistCSVDF3.createOrReplaceTempView(\"userArtistCSVDF3\")\n",
    "artistAliasFinal.createOrReplaceTempView(\"artistAliasFinal\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# badid 목록 보기\n",
    "%%sparksql sql_df\n",
    "\n",
    "SELECT\n",
    "    distinct(badid)\n",
    "FROM\n",
    "    artistAliasFinal\n",
    "limit 20;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sql_df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# badid 개수 및 목록 보기\n",
    "\n",
    "# artistAliasFinal.select(distinct($\"badid\")).show() \n",
    "# functions에 distinct 함수 자체가 아직 없어요.... error: not found: value distinct\n",
    "artistAliasFinal.select(F.count_distinct(artistAliasFinal.badid)).show() #--functions에 countDistinct 함수 존재함.... 정상동작....\n",
    "\n",
    "#artistAliasFinal.selectExpr(\"distinct(badid)\").show()  //--distinct(col) 에러발생.... AnalysisException: Undefined function: 'distinct'....\n",
    "artistAliasFinal.selectExpr(\"count(distinct(badid))\").show()  #count(distinct(col)) 정상동작....\n",
    "\n",
    "\n",
    "spark.sql(\"select distinct(badid) from artistAliasFinal\").show()  #distinct(col) 정상동작....\n",
    "spark.sql(\"select count(distinct(badid)) from artistAliasFinal\").show()  #count(distinct(col)) 정상동작...."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# badid 갯수 확인\n",
    "print(artistAliasFinal.count())\n",
    "artistAliasFinal.selectExpr(\"count(distinct(badid))\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "badid를 goodid로 변경하기 위한 join 테스트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%sparksql badTogood_df_1\n",
    "\n",
    "select\n",
    "    *\n",
    "from\n",
    "    userArtistCSVDF3 ua\n",
    "    left outer join\n",
    "    artistAliasFinal aa\n",
    "    on \n",
    "    ua.artistid = aa.badid\n",
    "where\n",
    "    True\n",
    "limit 20;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "badTogood_df_1.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%sparksql badTogood_df_2\n",
    "\n",
    "select \n",
    "    ua.*,\n",
    "    aa.*,\n",
    "    case\n",
    "        when aa.badid is not null then aa.goodid\n",
    "        else ua.artistid\n",
    "    end\n",
    "    as artistid2\n",
    "from\n",
    "    userArtistCSVDF3 ua\n",
    "    left outer join\n",
    "    artistAliasFinal aa\n",
    "    on \n",
    "    ua.artistid = aa.badid\n",
    "where\n",
    "    true\n",
    "limit 20;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "badTogood_df_2.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%sparksql badTogood_df_3\n",
    "\n",
    "select \n",
    "    ua.userid,\n",
    "    case\n",
    "        when aa.badid is not null then aa.goodid\n",
    "        else ua.artistid\n",
    "    end\n",
    "    as artistid,\n",
    "    ua.playcount\n",
    "from\n",
    "    userArtistCSVDF3 ua\n",
    "    left outer join\n",
    "    artistAliasFinal aa\n",
    "    on \n",
    "    ua.artistid = aa.badid\n",
    "where\n",
    "    true\n",
    "--and aa.badid is not null\n",
    "limit 20;\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "badTogood_df_3.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistCSVDF4 = spark.sql('select ua.userid, case when aa.badid is not null then aa.goodid else ua.artistid end as artistid, ua.playcount from userArtistCSVDF3 ua left outer join artistAliasFinal aa on ua.artistid = aa.badid where true')\n",
    "\n",
    "print(userArtistCSVDF4.count())\n",
    "userArtistCSVDF4.printSchema()\n",
    "userArtistCSVDF4.show()\n",
    "\n",
    "# scala\n",
    "# val userArtistCSVDF4 = spark.sql(\"\"\"\n",
    "# \n",
    "# select \n",
    "#     ua.userid,\n",
    "#     case\n",
    "#         when aa.badid is not null then aa.goodid\n",
    "#         else ua.artistid\n",
    "#     end\n",
    "#     as artistid,\n",
    "#     ua.playcount\n",
    "# from\n",
    "#     userArtistCSVDF3 ua\n",
    "#     left outer join\n",
    "#     artistAliasFinal aa\n",
    "#     on \n",
    "#     ua.artistid = aa.badid\n",
    "# where\n",
    "#     true\n",
    "# --and aa.badid is not null\n",
    "# \"\"\")\n",
    "# \n",
    "# println(userArtistCSVDF4.count())\n",
    "# userArtistCSVDF4.printSchema()\n",
    "# userArtistCSVDF4.show()\n",
    "# z.show(userArtistCSVDF4.limit(20))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SQL문으로 작업한 내용을 DataFrame의 API로 작업하기 => badid를 goodid로 바꾼 최종 데이터"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistFinal = userArtistCSVDF3.join(artistAliasFinal, userArtistCSVDF3.artistid== artistAliasFinal.badid, \"left_outer\").withColumn(\"artistid2\", F.expr(\"case when badid is not null then goodid else artistid end\")).withColumn(\"artistid2\", F.when(F.col(\"badid\").isNotNull(), F.col(\"goodid\")).otherwise(F.col(\"artistid\"))).select('userid', F.col('artistid2').alias(\"artistid\"), 'playcount')\n",
    "# userArtistFinal = spark.sql('select * from userArtistCSVDF3 as ua left outer join artistAliasFinal as aa on ua.artistid = aa.badid').withColumn(\"artistid2\", F.expr(\"case when badid is not null then goodid else artistid end\")).withColumn(\"artistid2\", F.when(F.col(\"aa.badid\").isNotNull(), F.col(\"aa.goodid\")).otherwise(F.col(\"ua.artistid\"))).select('userid', F.col('artistid2').alias('artistid'), 'playcount')\n",
    "\n",
    "userArtistFinal.persist(StorageLevel.MEMORY_ONLY)    \n",
    "print(userArtistFinal.count())\n",
    "userArtistFinal.printSchema()\n",
    "userArtistFinal.show()\n",
    "\n",
    "userArtistFinal.createOrReplaceTempView(\"userArtistFinal\")\n",
    "\n",
    "# scala\n",
    "# val userArtistFinal = userArtistCSVDF3.as(\"ua\")\n",
    "#     .join(artistAliasFinal.as(\"aa\"), $\"ua.artistid\" === $\"aa.badid\", \"left_outer\")\n",
    "# //  .withColumn(\"artistid2\", case when $\"aa.badid\" is not null then $\"aa.goodid\" else $\"ua.artistid\" end)  //--case 함수 제공 안함....\n",
    "#     .withColumn(\"artistid2\", expr(\"case when aa.badid is not null then aa.goodid else ua.artistid end\"))  //--expr 함수 사용....\n",
    "#     .withColumn(\"artistid2\", when(col(\"aa.badid\").isNotNull, col(\"aa.goodid\")).otherwise(col(\"ua.artistid\")))  //--when 함수 사용....\n",
    "#     .select('userid, 'artistid2 as \"artistid\", 'playcount)\n",
    "# \n",
    "# userArtistFinal.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)    \n",
    "# println(userArtistFinal.count())\n",
    "# userArtistFinal.printSchema()\n",
    "# userArtistFinal.show()\n",
    "# z.show(userArtistFinal.limit(20))\n",
    "# \n",
    "# userArtistFinal.createOrReplaceTempView(\"userArtistFinal\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 걸러진 데이터 건수 확인\n",
    "print(userArtistCSVDF3.count() - userArtistFinal.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 걸러진 badid 데이터 건수 확인\n",
    "print(userArtistCSVDF3.select(\"artistid\").distinct().count() - userArtistFinal.select(\"artistid\").distinct().count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "badid를 goodid로 바꾼 후 같은 아티스트에 대한 playcount가 2개 이상인 데이터 확인 #1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%sparksql plc_check_1\n",
    "\n",
    "select \n",
    "    userid,\n",
    "    artistid,\n",
    "    count(playcount) as cnt\n",
    "from\n",
    "    userArtistFinal\n",
    "group by userid, artistid\n",
    "having\n",
    "    True\n",
    "and cnt > 1\n",
    "order by cnt DESC\n",
    "limit 20;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%sparksql plc_check_2\n",
    "\n",
    "select \n",
    "    *\n",
    "from\n",
    "    userArtistFinal\n",
    "where\n",
    "    True\n",
    "and userid = 2133748\n",
    "and artistid = 1018110\n",
    ";\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%sparksql plc_check_3\n",
    "\n",
    "select\n",
    "    *\n",
    "from \n",
    "    artistAliasFinal\n",
    "where\n",
    "    True\n",
    "and goodid = 1018110\n",
    ";\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plc_check_3.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "같은 아티스트에 대한 plyacount 합치기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%sparksql plc_check_4\n",
    "\n",
    "select \n",
    "    userid,\n",
    "    artistid,\n",
    "    sum(playcount) as playcount\n",
    "from\n",
    "    userArtistFinal\n",
    "group by userid, artistid\n",
    "order by playcount desc\n",
    "limit 20;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "같은 아티스트에 대한 playcount 합치기 ( DF API로 작업하기 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistFinal2 = userArtistFinal.groupBy(\"userid\", \"artistid\").agg(F.sum('playcount').alias('playcount')).filter('playcount <= 64800') # 이전에 설정한 max playcount 값인 '64800'로 데이터 걸러내기\n",
    "\n",
    "userArtistFinal2.printSchema()\n",
    "userArtistFinal2.show()\n",
    "\n",
    "# scala\n",
    "# val userArtistFinal2 = userArtistFinal\n",
    "#     .groupBy(\"userid\", \"artistid\")\n",
    "#     .agg(sum(\"playcount\").as(\"playcount\"))\n",
    "#     .filter(\"playcount <= 64800\")  //--저희의 max playcount 값 '64800'로 데이터 걸러내기....\n",
    "# \n",
    "# userArtistFinal2.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)    \n",
    "# println(userArtistFinal2.count())\n",
    "# userArtistFinal2.printSchema()\n",
    "# userArtistFinal2.show()\n",
    "# z.show(userArtistFinal2.limit(20))\n",
    "# \n",
    "# userArtistFinal2.createOrReplaceTempView(\"userArtistFinal2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  playcount가 합쳐진 데이터 건수 확인\n",
    "print(userArtistFinal.count() - userArtistFinal2.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 최종 학습 데이터 캐시\n",
    "\n",
    "userArtistFinal2.cache() # userid_artistid_playcount\n",
    "\n",
    "userArtistFinal2.persist(StorageLevel.MEMORY_ONLY) \n",
    "userArtistFinal2.createOrReplaceTempView(\"userArtistFinal2\")\n",
    "print(userArtistFinal2.count())\n",
    "\n",
    "# 기타 데이터 캐시\n",
    "artistFinal.cache()  # artistid_artistname\n",
    "print(artistFinal.count())\n",
    "artistAliasFinal.persist()  # badid_goodid\n",
    "print(artistAliasFinal.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 최종 학습 데이터 캐시 해제\n",
    "userArtistFinal2.unpersist()  #userid_artistid_playcount\n",
    "\n",
    "# 기타 데이터 캐시 해제\n",
    "artistFinal.unpersist()  #artistid_artistname\n",
    "artistAliasFinal.unpersist()  #badid_goodid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cassandra 에 userArtistFinal2 저장하기 **\n",
    "- apache-cassandra-4.0.11/bin/cassandra\n",
    "- Table 생성"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cassandra 와 연결\n",
    "# 참고사이트 : https://docs.datastax.com/en/developer/python-driver/3.24/getting_started/\n",
    "\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'], port=9042)\n",
    "    session = cluster.connect(keyspace='mykeyspace')\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "session.execute('describe keyspaces').all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [Cassandra] Table List 조회\n",
    "session.execute('describe tables').all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [Cassandra] userArtistFinal2 Table 내용 확인\n",
    "session.execute('select * from user_artist_data limit 20').all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [Cassandra] Table 스키마 확인\n",
    "\n",
    "session.execute(\"SELECT column_name,type FROM system_schema.columns WHERE keyspace_name ='mykeyspace' and table_name='user_artist_data'\").all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistFinal2.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Cassandra] 최종 학습 데이터 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Table 생성\n",
    "session.execute(\"CREATE TABLE user_artist_data2 ( userid int , artistid int , playcount int, primary key (userid, artistid))\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Table 에 data insert 하기\n",
    "insert_query = session.prepare(\"INSERT INTO user_artist_data2 (userid, artistid, playcount) VALUES (?, ?, ?)\")\n",
    "parameters = [(userid, artistid, playcount) for userid, artistid, playcount in userArtistFinal2.limit(100000).toLocalIterator()] # 시간 단축을 위해, 데이터 일부만 저장\n",
    "execute_concurrent_with_args(session, insert_query, parameters, concurrency=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. ALS 알고리즘 학습\n",
    "\n",
    "\n",
    "```\n",
    "추천 알고리즘 인 ALS를 이용하여 모델 생성 및 추천 실행....\n",
    " \n",
    "ALS(\"Alternating Least Squares\", \"교차 최소 제곱\") 알고리즘은 Netflix Prize에서 \n",
    "발표된 논문인 \"Collaborative Filtering for the Implicit Feedback Datasets\"과, \n",
    "\"Large-scale Parallel Collaborative Filtering for the Netflix Prize\"에서 주로 사용된 방식....\n",
    "\n",
    "Spark MLlib의 ALS는 이 두 논문에서 아이디어를 가져와 구현....\n",
    "\n",
    "- Collaborative Filtering for Implicit Feedback Datasets\n",
    "(http://yifanhu.net/PUB/cf.pdf)\n",
    "\n",
    "Large-scale Parallel Collaborative Filtering for the Netflix Prize\n",
    "(http://shiftleft.com/mirrors/www.hpl.hp.com/personal/Robert_Schreiber/papers/2008%20AAIM%20Netflix/netflix_aaim08(submitted).pdf)\n",
    "```\n",
    "\n",
    "#### [Matrix Completion]\n",
    "\n",
    "![Matrix Completion](https://d3i71xaburhd42.cloudfront.net/07d2577de9fb4bb5cbd7424ce5d64e6ef0dd78a0/30-Figure2.1-1.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### [ALS(\"Alternating Least Squares\", \"교차 최소 제곱\")]\n",
    "\n",
    "![ALS](https://miro.medium.com/max/1400/1*ezY_g30VQ8MTGpDwd3z56w.png)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Cassandra] 최종 학습 데이터 로딩 + Cache"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistFinal3 = spark.createDataFrame(data=session.execute(\"SELECT * FROM user_artist_data\").all(), schema = ['userid', 'artistid', 'playcount'])\n",
    "#최종 학습 데이터 캐시\n",
    "userArtistFinal3.persist(StorageLevel.MEMORY_ONLY) #userid_artistid_playcount\n",
    "print(userArtistFinal3.count())\n",
    "\n",
    "userArtistFinal3.printSchema()\n",
    "userArtistFinal3.show()\n",
    "\n",
    "# scala\n",
    "# val userArtistFinal3 = spark.table(\"mycatalog.mykeyspace.user_artist_data\")\n",
    "# \n",
    "# //--최종 학습 데이터 캐시....\n",
    "# userArtistFinal3.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY) //--userid_artistid_playcount....\n",
    "# println(userArtistFinal3.count())\n",
    "# \n",
    "# userArtistFinal3.printSchema\n",
    "# userArtistFinal3.show"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[캐시해제] 최종 학습 데이터 캐시 해제"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 최종 학습 데이터 캐시 해제\n",
    "userArtistFinal3.unpersist()  # userid_artistid_playcount"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ALS 알고리즘 파라미터 세팅"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "als = ALS(rank=10,coldStartStrategy='drop',seed=11, alpha=40, regParam=0.1, maxIter=5, implicitPrefs=True, ratingCol='playcount', itemCol='artistid', userCol='userid') # als = ALS().setUserCol(\"userid\").setItemCol(\"artistid\").setRatingCol(\"playcount\").setImplicitPrefs(True).setMaxIter(5).setRegParam(0.1).setAlpha(40).setRank(10).setColdStartStrategy(\"drop\").setSeed(11)\n",
    "\n",
    "# scala\n",
    "# val als = new ALS()\n",
    "#     .setUserCol(\"userid\")\n",
    "#     .setItemCol(\"artistid\")\n",
    "#     .setRatingCol(\"playcount\")\n",
    "#     .setImplicitPrefs(true)\n",
    "#     .setMaxIter(5)\n",
    "#     .setRegParam(0.1)  //--hyper parameter.... Param for regularization parameter (>= 0).\n",
    "#     .setAlpha(40)  //--hyper parameter.... Param for the alpha parameter in the implicit preference formulation (nonnegative). Default: 1.0\n",
    "#     .setRank(10)  //--hyper parameter.... Param for rank of the matrix factorization (positive). Default: 10\n",
    "#     .setColdStartStrategy(\"drop\")  //--Param for strategy for dealing with unknown or new users/items at prediction time. Supported values: nan,drop. (default: nan)\n",
    "#     .setSeed(11L)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 파라미터 내용 보기\n",
    "print(\"\\n>>>> als.explainParams()\")\n",
    "print(als.explainParams())\n",
    "\n",
    "print(\"\\n\\n>>>> als.extractParamMap()\")\n",
    "als.extractParamMap()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistFinal3.printSchema()\n",
    "\n",
    "# ALS 알고리즘 학습\n",
    "alsModel = als.fit(userArtistFinal3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 추천\n",
    "\n",
    "- 존재하는 사용자 vs. 존재하지 않는(New) 사용자\n",
    "- 모든 사용자 : 아티스트 쌍에 대해 모델 적용\n",
    "- 모든 사용자에 대한 추천\n",
    "- 모든 아티스트에 대한 추천\n",
    "- 아티스트 이름도 같이 보기\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "테스트용 사용자 추출"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userArtistFinal3.groupBy(\"userid\").agg(F.count(\"artistid\").alias(\"count_artist\"), F.sum(\"playcount\").alias(\"sum_playcount\")).where(\"count_artist >= 20\").orderBy(F.col(\"count_artist\").asc(), F.col(\"sum_playcount\").desc()).show()\n",
    "\n",
    "# scala\n",
    "# userArtistFinal3\n",
    "#     .groupBy(\"userid\")\n",
    "#     .agg(count(\"artistid\").as(\"count_artist\"), sum(\"playcount\").as(\"sum_playcount\"))\n",
    "#     .where(\"count_artist >= 20\")\n",
    "#     .orderBy($\"count_artist\".asc, $\"sum_playcount\".desc)\n",
    "#     .show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습된 ALS Model로 추천해보기 > Exist User & New User (w/ 아티스트 이름....)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userDS =spark.createDataFrame([1001440, 2010008, 987654321], IntegerType()).toDF('userID')\n",
    "userDS.printSchema()\n",
    "userDS.show()\n",
    "\n",
    "# 특정 사용자를 위한 추천 5개....\n",
    "recommendedForSomeUsersDF = alsModel.recommendForUserSubset(userDS, 5)\n",
    "recommendedForSomeUsersDF.printSchema()\n",
    "recommendedForSomeUsersDF.show()\n",
    "\n",
    "# explode....\n",
    "recommendedForSomeUsersDF2 = recommendedForSomeUsersDF.withColumn(\"recommend\", F.explode(\"recommendations\")).withColumn(\"artistid\", F.col('recommend').artistid).withColumn(\"rating\",  F.col(\"recommend\").rating)\n",
    "\n",
    "recommendedForSomeUsersDF2.printSchema()\n",
    "recommendedForSomeUsersDF2.show()\n",
    "print(recommendedForSomeUsersDF2.count())\n",
    "\n",
    "# 불필요한 colum drop하기\n",
    "recommendedForSomeUsersDF3 = recommendedForSomeUsersDF2.drop(\"recommendations\", \"recommend\")\n",
    "\n",
    "recommendedForSomeUsersDF3.printSchema()\n",
    "recommendedForSomeUsersDF3.show()\n",
    "print(recommendedForSomeUsersDF3.count())\n",
    "\n",
    "# recommendedForSomeUsersDF3 와 artistFinal DF 를 join 하여, artistid 로 artis name 가져오기\n",
    "recommendedForSomeUsersDF4 = recommendedForSomeUsersDF3.join(artistFinal, 'artistid').orderBy(F.col(\"userid\").asc(), F.col(\"rating\").desc())\n",
    "recommendedForSomeUsersDF4.show()\n",
    "\n",
    "# scala\n",
    "# val userDS = Seq(1001440, 2010008, 987654321)\n",
    "#     .toDF(\"userID\")\n",
    "#     .as[Int]  //--Dataset으로 형변환.... by Encoder....\n",
    "# \n",
    "# userDS.printSchema\n",
    "# userDS.show(false)\n",
    "# \n",
    "# //--특정 사용자를 위한 추천 5개....\n",
    "# val recommendedForSomeUsersDF = alsModel.recommendForUserSubset(userDS, 5)\n",
    "# recommendedForSomeUsersDF.printSchema\n",
    "# recommendedForSomeUsersDF.show(false)\n",
    "# \n",
    "# //--explode....\n",
    "# val recommendedForSomeUsersDF2 = recommendedForSomeUsersDF\n",
    "#     .withColumn(\"recommend\", explode($\"recommendations\"))\n",
    "#     .withColumn(\"artistid\", $\"recommend.artistid\")\n",
    "#     .withColumn(\"rating\", $\"recommend.rating\")\n",
    "# \n",
    "# recommendedForSomeUsersDF2.printSchema()\n",
    "# recommendedForSomeUsersDF2.show(false)\n",
    "# println(recommendedForSomeUsersDF2.count())\n",
    "# \n",
    "# //--drop....\n",
    "# val recommendedForSomeUsersDF3 = recommendedForSomeUsersDF2\n",
    "#     .drop(\"recommendations\", \"recommend\")\n",
    "# \n",
    "# recommendedForSomeUsersDF3.printSchema()\n",
    "# recommendedForSomeUsersDF3.show(false)\n",
    "# println(recommendedForSomeUsersDF3.count())\n",
    "# \n",
    "# //--join w/artistFinal....\n",
    "# val recommendedForSomeUsersDF4 = recommendedForSomeUsersDF3.as(\"reco\")\n",
    "#     .join(artistFinal.as(\"art\"), $\"reco.artistid\" === $\"art.artistid\")\n",
    "#     .orderBy($\"userid\".asc, $\"rating\".desc)\n",
    "# \n",
    "# recommendedForSomeUsersDF4.show(false)\n",
    "# z.show(recommendedForSomeUsersDF4)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "그럴싸한 추천을 제공하는지 확인해보기 > 기존 플레이한 아티스트 vs. 추천된 아티스트 비교"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userArtistFinal3.createOrReplaceTempView(\"userArtistFinal3\");\n",
    "artistFinal.createOrReplaceTempView(\"artistFinal\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "historyForSomeUsersDF = spark.sql('select * from (select * from userArtistFinal3 where userid in (1001440, 2010008)) as history join artistFinal as art on history.artistid = art.artistid').orderBy(F.col(\"userid\").asc(), F.col(\"playcount\").desc())\n",
    "\n",
    "historyForSomeUsersDF.show(40, False)\n",
    "\n",
    "# scala\n",
    "# val historyForSomeUsersDF = userArtistFinal3\n",
    "#     .where(\"userid in (1001440, 2010008)\").as(\"history\")\n",
    "#     .join(artistFinal.as(\"art\"), $\"history.artistid\" === $\"art.artistid\")\n",
    "#     .orderBy($\"userid\".asc, $\"playcount\".desc)\n",
    "# \n",
    "# historyForSomeUsersDF.show(40, false)\n",
    "# z.show(historyForSomeUsersDF)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "모든 (사용자 : 아티스트) 쌍에 대해 모델 적용하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "predictionsDF = alsModel.transform(userArtistFinal3)\n",
    "predictionsDF.printSchema()\n",
    "\n",
    "predictionsDF.orderBy(F.col(\"prediction\").desc()).show()\n",
    "predictionsDF.orderBy(F.col(\"prediction\").asc()).show()\n",
    "\n",
    "# scala\n",
    "# val predictionsDF = alsModel.transform(userArtistFinal3)\n",
    "# predictionsDF.printSchema\n",
    "# \n",
    "# predictionsDF\n",
    "#     .orderBy($\"prediction\".desc)\n",
    "#     .show(false)\n",
    "# \n",
    "# predictionsDF\n",
    "#     .orderBy($\"prediction\".asc)\n",
    "#     .show(false)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 모델 평가\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델 평가를 위한 Evaluator 정의 (평가지표 : RMSE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "regEval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"playcount\", metricName=\"rmse\" )\n",
    "\n",
    "# scala\n",
    "# val regEval = new RegressionEvaluator()\n",
    "#     .setLabelCol(\"playcount\")\n",
    "#     .setPredictionCol(\"prediction\")\n",
    "#     .setMetricName(\"rmse\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델 평가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rmse = regEval.evaluate(predictionsDF)\n",
    "\n",
    "print(rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. 하이퍼 파라미터 튜닝"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pipeline 알고리즘 정의 > stage 1개 + ALS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "pipeline = Pipeline(stages=[als]) # 다른 방법 pipeline = Pipeline.setStages(als)\n",
    "\n",
    "# scala\n",
    "# val pipeline = new Pipeline()\n",
    "#     .setStages(Array(als))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "하이퍼 파라미터 조합을 ParamMap으로 구성하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "paramMaps = ParamGridBuilder().addGrid(als.alpha, (40.0, 10.0, 5.0, 1.0)).addGrid(als.rank, (2,3,10)).addGrid(als.regParam, (1.0, 0.01)).build()\n",
    "\n",
    "print(paramMaps)\n",
    "\n",
    "# scala\n",
    "# val paramMaps = new ParamGridBuilder()\n",
    "#     .addGrid(als.alpha, Array(40.0,10.0, 5.0, 1.0))\n",
    "#     .addGrid(als.rank, Array(2, 3, 10))\n",
    "#     .addGrid(als.regParam, Array(1.0, 0.01))\n",
    "#     .build()\n",
    "# \n",
    "# println(paramMaps.mkString(\", \"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CrossValidator 정의"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "\"\"\"\n",
    "estimator : ML 알고리즘\n",
    "estimatorParamMaps : 튜닝하고자 하는 하이퍼 파라미터 조합\n",
    "evaluator : 모델을 평가하는 평가자\n",
    "numFolds : 데이터를 나누는 기준\n",
    "\"\"\"\n",
    "cv = CrossValidator(estimator=pipeline,estimatorParamMaps=paramMaps,evaluator=regEval,numFolds=2 )  \n",
    "\n",
    "# scala\n",
    "# val cv = new CrossValidator()\n",
    "#     .setEstimator(pipeline)  //--ML 알고리즘.... Pipeline....\n",
    "#     .setEstimatorParamMaps(paramMaps)  //--튜닝하고자 하는 하이퍼 파라미터 조합....\n",
    "#     .setEvaluator(regEval)  //--모델을 평가하는 평가자....\n",
    "#     .setNumFolds(2)  //--데이터를 나누는 기준....\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train dataset 과 test dataset 분리하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "(trainDS, testDS) = userArtistFinal3.randomSplit([0.7, 0.3], 11)\n",
    "print(userArtistFinal3.count())\n",
    "\n",
    "trainDS.persist(StorageLevel.MEMORY_ONLY)\n",
    "print(trainDS.count())\n",
    "\n",
    "testDS.persist(StorageLevel.MEMORY_ONLY)\n",
    "print(testDS.count())\n",
    "\n",
    "# scala\n",
    "# val Array(trainDS, testDS) = userArtistFinal3.randomSplit(Array(0.7, 0.3), 11L)\n",
    "# \n",
    "# println(userArtistFinal3.count)\n",
    "# \n",
    "# trainDS.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)\n",
    "# println(trainDS.count)\n",
    "# \n",
    "# testDS.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)\n",
    "# println(testDS.count)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CrossValidator 학습 > Took 1 min 50 sec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cvModel = cv.fit(trainDS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best 모델 조회"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "print(\"\\n>>>> Best Model : \\n\" + str(cvModel.bestModel))\n",
    "print(\"\\n>>>> Avg Metrics :\", *cvModel.avgMetrics, sep='\\n' )\n",
    "print(\"\\n>>>> Estimator ParamMaps :\", *cvModel.getEstimatorParamMaps(), sep='\\n')\n",
    "\n",
    "# scala\n",
    "# print(\"\\n>>>> Best Model : \\n\" + cvModel.bestModel)\n",
    "# print(\"\\n>>>> Avg Metrics : \\n\" + cvModel.avgMetrics.mkString(\"\\n\"))\n",
    "# print(\"\\n>>>> Estimator ParamMaps : \\n\" + cvModel.getEstimatorParamMaps.mkString(\"\\n\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "파라미터 조합별 metric 점수 매핑하여 보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "zippedParamAndMetrics = zip(cvModel.getEstimatorParamMaps(),cvModel.avgMetrics)\n",
    "print(*(\"\\n>>>> Zipped Param And Metrics : \\n\" , *zippedParamAndMetrics ),sep='\\n')\n",
    "\n",
    "# scala\n",
    "# val zippedParamAndMetrics = cvModel.getEstimatorParamMaps\n",
    "#     .zip(cvModel.avgMetrics)\n",
    "#     .sortBy(_._2)\n",
    "# \n",
    "# println(\"\\n>>>> Zipped Param And Metrics : \\n\" + zippedParamAndMetrics.mkString(\"\\n\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델 평가 (RMSE....) #2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "predictionsDF2 = cvModel.transform(testDS)\n",
    "predictionsDF2.show()\n",
    "\n",
    "rmse2 = regEval.evaluate(predictionsDF2)\n",
    "print(rmse2)\n",
    "\n",
    "# scala\n",
    "# val predictionsDF2 = cvModel.transform(testDS)\n",
    "# predictionsDF2.show()\n",
    "# \n",
    "# val rmse2 = regEval.evaluate(predictionsDF2)\n",
    "# println(rmse2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CrossValidator 모델 HDFS에 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "cvModel.write().overwrite().save(\"hdfs://localhost:9000/model/audio/profiledata_06-May-2005/als_crossvalidator\")\n",
    "\n",
    "# scala\n",
    "# cvModel.write.overwrite.save(\"hdfs://spark-master-01:9000/model/audio/profiledata_06-May-2005/als_crossvalidator\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "실제 Best 모델인 ALSModel 추출하여 HDFS에 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "print(f\">>>> CrossValidatorModel : {cvModel} \\n\")\n",
    "print(f\">>>> CrossValidatorModel.bestModel : {cvModel.bestModel}\\n\")\n",
    "print(f\">>>> PipelineModel.stages(0) : {cvModel.bestModel.stages[0]}\\n\")\n",
    "\n",
    "# ALSModel\n",
    "alsBestModel = cvModel.bestModel.stages[0]\n",
    "\n",
    "# 실제 Best 모델인 ALSModel을 HDFS에 저장 -> 왜? ALSModel에 있는 recommendForUserSubset() API와 같은 추천에 특화된 API를 사용하려구\n",
    "alsBestModel.write().overwrite().save(\"hdfs://localhost:9000/model/audio/profiledata_06-May-2005/als\")\n",
    "\n",
    "# scala\n",
    "# println(\"\\n>>>> CrossValidatorModel : \\n\" + cvModel)\n",
    "# println(\"\\n>>>> CrossValidatorModel.bestModel : \\n\" + cvModel.bestModel)\n",
    "# \n",
    "# //--Cast as PipelineModel.... asInstanceOf[type]....\n",
    "# val pipelineBestModel = cvModel.bestModel.asInstanceOf[PipelineModel]\n",
    "# \n",
    "# println(\"\\n>>>> PipelineModel.stages(0) : \\n\" + pipelineBestModel.stages(0))\n",
    "# \n",
    "# //--Cast as ALSModel.... asInstanceOf[type]....\n",
    "# val alsBestModel = pipelineBestModel.stages(0).asInstanceOf[ALSModel]\n",
    "# \n",
    "# alsBestModel\n",
    "#     .write\n",
    "#     .overwrite\n",
    "#     .save(\"hdfs://spark-master-01:9000/model/audio/profiledata_06-May-2005/als\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "HDFS에 저장된 Best ALSModel을 로딩하여 내용보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#loadedBestALSModel = ALS.load(\"hdfs://spark-master-01:9000/model/audio/profiledata_06-May-2005/als\")\n",
    "loadedBestALSModel = alsModel.load(\"hdfs://localhost:9000/model/audio/profiledata_06-May-2005/als\")\n",
    "\n",
    "print(\"\\n>>>> model.extractParamMap : \\n\" + str(loadedBestALSModel.extractParamMap()))\n",
    "print(\"\\n>>>> model.explainParams : \\n\" + str(loadedBestALSModel.explainParams()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "로딩된 Best ALSModel로 추천하기 > ALSModel.recommendForUserSubset(DS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "userDS2 =spark.createDataFrame([1001440, 2010008, 987654321], IntegerType()).toDF('userID')  # Dataset으로 형변환.... by Encoder....\n",
    "\n",
    "userDS2.printSchema()\n",
    "userDS2.show()\n",
    "\n",
    "# 특정 사용자를 위한 추천 5개\n",
    "recommendedForSomeUsersDF2 = loadedBestALSModel.recommendForUserSubset(userDS2, 5)\n",
    "recommendedForSomeUsersDF2.printSchema()\n",
    "recommendedForSomeUsersDF2.show()\n",
    "\n",
    "# scala\n",
    "# val userDS2 = Seq(1001440, 2010008, 987654321)\n",
    "#     .toDF(\"userID\")\n",
    "#     .as[Int]  //--Dataset으로 형변환.... by Encoder....\n",
    "# \n",
    "# userDS2.printSchema\n",
    "# userDS2.show(false)\n",
    "# \n",
    "# //--특정 사용자를 위한 추천 5개....\n",
    "# val recommendedForSomeUsersDF2 = loadedBestALSModel.recommendForUserSubset(userDS2, 5)\n",
    "# recommendedForSomeUsersDF2.printSchema\n",
    "# recommendedForSomeUsersDF2.show(false)\n",
    "# z.show(recommendedForSomeUsersDF2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "로딩된 Best ALSModel로 추천하기 > ALSModel.recommendForUserSubset(DS) (w/ 아티스트 이름)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommendedForSomeUsersDF2.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "# explode\n",
    "recommendedForSomeUsersDF3 = recommendedForSomeUsersDF2.withColumn(\"recommend\", F.explode(\"recommendations\")).withColumn(\"artistid\", F.col(\"recommend.artistid\")).withColumn(\"rating\", F.col(\"recommend.rating\"))\n",
    "\n",
    "recommendedForSomeUsersDF3.printSchema()\n",
    "recommendedForSomeUsersDF3.show()\n",
    "print(recommendedForSomeUsersDF3.count())\n",
    "\n",
    "# scala\n",
    "# //--explode....\n",
    "# val recommendedForSomeUsersDF3 = recommendedForSomeUsersDF2\n",
    "#     .withColumn(\"recommend\", explode($\"recommendations\"))\n",
    "#     .withColumn(\"artistid\", $\"recommend.artistid\")\n",
    "#     .withColumn(\"rating\", $\"recommend.rating\")\n",
    "# \n",
    "# recommendedForSomeUsersDF3.printSchema()\n",
    "# recommendedForSomeUsersDF3.show(false)\n",
    "# println(recommendedForSomeUsersDF3.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "# drop\n",
    "recommendedForSomeUsersDF4 = recommendedForSomeUsersDF3.drop(\"recommendations\", \"recommend\")\n",
    "\n",
    "recommendedForSomeUsersDF4.printSchema()\n",
    "recommendedForSomeUsersDF4.show()\n",
    "print(recommendedForSomeUsersDF4.count())\n",
    "\n",
    "# scala\n",
    "# //--drop....\n",
    "# val recommendedForSomeUsersDF4 = recommendedForSomeUsersDF3\n",
    "#     .drop(\"recommendations\", \"recommend\")\n",
    "# \n",
    "# recommendedForSomeUsersDF4.printSchema()\n",
    "# recommendedForSomeUsersDF4.show(false)\n",
    "# println(recommendedForSomeUsersDF4.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "# recommendedForSomeUsersDF33 과 artistFinal df join 하기\n",
    "recommendedForSomeUsersDF5 = recommendedForSomeUsersDF4.join(artistFinal, 'artistid').sort(F.asc('userid'), F.desc('rating')) #spark.sql('select * from recommendedForSomeUsersDF33 as reco join artistFinal as art on reco.artistid = art.artistid').orderBy(F.col(\"userid\").asc(), F.col(\"rating\").desc())\n",
    "\n",
    "recommendedForSomeUsersDF5.show()\n",
    "\n",
    "# scala\n",
    "# //--join w/artistFinal....\n",
    "# val recommendedForSomeUsersDF5 = recommendedForSomeUsersDF4.as(\"reco\")\n",
    "#     .join(artistFinal.as(\"art\"), $\"reco.artistid\" === $\"art.artistid\")\n",
    "#     .orderBy($\"userid\".asc, $\"rating\".desc)\n",
    "# \n",
    "# recommendedForSomeUsersDF5.show(false)\n",
    "# z.show(recommendedForSomeUsersDF5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Redis] 모든 사용자를 위한 아티스트 5건 추천 #1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "recommendedForAllUsersDF = loadedBestALSModel.recommendForAllUsers(5)\n",
    "\n",
    "recommendedForAllUsersDF.printSchema()\n",
    "recommendedForAllUsersDF.show()\n",
    "print(recommendedForAllUsersDF.count)\n",
    "\n",
    "# scala\n",
    "# val recommendedForAllUsersDF = loadedBestALSModel.recommendForAllUsers(5)\n",
    "# \n",
    "# recommendedForAllUsersDF.printSchema\n",
    "# recommendedForAllUsersDF.show(false)\n",
    "# println(recommendedForAllUsersDF.count)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Redis] 모든 사용자를 위한 아티스트 5건 추천 #2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "recommendedForAllUsersDF2 = recommendedForAllUsersDF.withColumn(\"recommendation\", F.explode(\"recommendations\")).withColumn(\"artistid\", F.col(\"recommendation.artistid\"))\n",
    "    \n",
    "recommendedForAllUsersDF2.printSchema()\n",
    "recommendedForAllUsersDF2.show()\n",
    "print(recommendedForAllUsersDF2.count)\n",
    "\n",
    "# scala\n",
    "# val recommendedForAllUsersDF2 = recommendedForAllUsersDF\n",
    "#     .withColumn(\"recommendation\", explode($\"recommendations\"))\n",
    "#     .withColumn(\"artistid\", $\"recommendation.artistid\")\n",
    "#     \n",
    "# recommendedForAllUsersDF2.printSchema\n",
    "# recommendedForAllUsersDF2.show(false)\n",
    "# println(recommendedForAllUsersDF2.count)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Redis] 모든 사용자를 위한 아티스트 5건 추천 #3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "recommendedForAllUsersDF3 = recommendedForAllUsersDF2.groupBy(\"userid\").agg(F.collect_list(\"artistid\").alias(\"artistid_list\")).withColumn(\"recommended_artistids\", F.array_join(F.col(\"artistid_list\"), \" \"))\n",
    "    \n",
    "recommendedForAllUsersDF3.printSchema()\n",
    "recommendedForAllUsersDF3.show()\n",
    "print(recommendedForAllUsersDF3.count)\n",
    "\n",
    "# scala\n",
    "# val recommendedForAllUsersDF3 = recommendedForAllUsersDF2\n",
    "#     .groupBy(\"userid\")\n",
    "#     .agg(collect_list(\"artistid\").as(\"artistid_list\"))\n",
    "#     .withColumn(\"recommended_artistids\", array_join(col(\"artistid_list\"), \" \"))\n",
    "#     \n",
    "# recommendedForAllUsersDF3.printSchema\n",
    "# recommendedForAllUsersDF3.show(false)\n",
    "# println(recommendedForAllUsersDF3.count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Redis] 모든 사용자를 위한 아티스트 5건 추천 #4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "recommendedForAllUsersDF4 = recommendedForAllUsersDF3.select( 'userid', 'recommended_artistids' )\n",
    "\n",
    "recommendedForAllUsersDF4.printSchema()\n",
    "recommendedForAllUsersDF4.show()\n",
    "print(recommendedForAllUsersDF4.count)\n",
    "\n",
    "# scala\n",
    "# val recommendedForAllUsersDF4 = recommendedForAllUsersDF3.select($\"userid\", $\"recommended_artistids\")\n",
    "# recommendedForAllUsersDF4.printSchema\n",
    "# recommendedForAllUsersDF4.show(false)\n",
    "# println(recommendedForAllUsersDF4.count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Redis] 모든 사용자를 위한 아티스트 5건 추천 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "recommendedForAllUsersDF4.write.format(\"org.apache.spark.sql.redis\").option(\"table\", \"user_artists\").option(\"key.column\", \"userid\").mode(\"append\").save()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Redis] 모든 사용자를 위한 아티스트 5건 추천 조회"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# python\n",
    "recommendedForAllUsersDF5 = spark.read.format(\"org.apache.spark.sql.redis\").option(\"table\", \"user_artists\").option(\"key.column\", \"userid\").load()\n",
    "\n",
    "recommendedForAllUsersDF5.printSchema()\n",
    "recommendedForAllUsersDF5.show()\n",
    "print(recommendedForAllUsersDF5.count)\n",
    "\n",
    "# scala\n",
    "# val recommendedForAllUsersDF5 = spark\n",
    "#     .read\n",
    "#     .format(\"org.apache.spark.sql.redis\")\n",
    "#     .option(\"table\", \"user_artists\")\n",
    "#     .option(\"key.column\", \"userid\")\n",
    "#     .load()\n",
    "# \n",
    "# recommendedForAllUsersDF5.printSchema\n",
    "# recommendedForAllUsersDF5.show(false)\n",
    "# println(recommendedForAllUsersDF5.count)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Redis] 특정 사용자를 위한 아티스트 5건 추천 조회"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python\n",
    "recommendedForAllUsersDF4 = spark.read.format(\"org.apache.spark.sql.redis\").option(\"keys.pattern\", \"user_artists:2101263\").option(\"key.column\", \"userid\").option(\"infer.schema\", True).load()\n",
    "\n",
    "recommendedForAllUsersDF4.printSchema()\n",
    "recommendedForAllUsersDF4.show()\n",
    "\n",
    "# scala\n",
    "# val recommendedForAllUsersDF4 = spark\n",
    "#     .read\n",
    "#     .format(\"org.apache.spark.sql.redis\")\n",
    "#     .option(\"keys.pattern\", \"user_artists:2127894\")\n",
    "#     .option(\"key.column\", \"userid\")\n",
    "#     .option(\"infer.schema\", true)\n",
    "#     .load()\n",
    "# \n",
    "# recommendedForAllUsersDF4.printSchema\n",
    "# recommendedForAllUsersDF4.show(false)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
